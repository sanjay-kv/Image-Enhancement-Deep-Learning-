{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6399,"status":"ok","timestamp":1681279831485,"user":{"displayName":"Sanjay K V","userId":"07954576096521181679"},"user_tz":-600},"id":"BnxHurCrmLVQ","outputId":"272c6711-eb8c-496e-cf94-9cd23edd3343"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'CURL'...\n","remote: Enumerating objects: 561, done.\u001b[K\n","remote: Counting objects: 100% (156/156), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 561 (delta 136), reused 142 (delta 131), pack-reused 405\u001b[K\n","Receiving objects: 100% (561/561), 99.60 MiB | 21.15 MiB/s, done.\n","Resolving deltas: 100% (316/316), done.\n"]}],"source":["\n","! git clone https://github.com/sjmoran/CURL\n","#! git clone https://github.com/deshwalmahesh/CURL---cpu-gpu"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1681279831487,"user":{"displayName":"Sanjay K V","userId":"07954576096521181679"},"user_tz":-600},"id":"fMj0k7BdmWis","outputId":"362117ec-8a74-48c7-da4c-c1655f4f2fa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/CURL\n"]}],"source":["cd ./CURL/"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7621,"status":"ok","timestamp":1681279839101,"user":{"displayName":"Sanjay K V","userId":"07954576096521181679"},"user_tz":-600},"id":"ldg6aFZ-mb-u"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import sys\n","import torch\n","import torchvision.transforms.functional as TF\n","import requests\n","from io import BytesIO\n","import matplotlib.pyplot as plt\n","\n","# Imports from the code written by authors inside modules\n","import model\n","import util\n","from util import ImageProcessing\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' #"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681279839102,"user":{"displayName":"Sanjay K V","userId":"07954576096521181679"},"user_tz":-600},"id":"-5YRWabOmq4Q"},"outputs":[],"source":["def resize(image, new_width_height = 1920, convert_RGB = True):\n","  '''\n","  Resize and return Given Image\n","  args:\n","    path: Image Path, BytesIO or the image \n","    new_width_height = Reshaped image's width and height. # If integer is given, it'll keep the aspect ratio as it is by shrinking the Bigger dimension (width or height) to the max of new_width_height  and then shring the smaller dimension accordingly \n","    convert_RGB: Whether to Convert the RGBA image to RGB (by default backgroud is white)\n","  '''\n","  image = Image.open(image) if isinstance(image, (str, BytesIO)) else image\n","  w, h = image.size\n","\n","  fixed_size = new_width_height if isinstance(new_width_height, int) else False\n","\n","  if fixed_size:\n","    if h \u003e w:\n","      fixed_height = fixed_size\n","      height_percent = (fixed_height / float(h))\n","      width_size = int((float(w) * float(height_percent)))\n","      image = image.resize((width_size, fixed_height), Image.NEAREST)\n","\n","    else:\n","      fixed_width = fixed_size\n","      width_percent = (fixed_width / float(w))\n","      height_size = int((float(h) * float(width_percent)))\n","      image = image.resize((fixed_width, height_size), Image.NEAREST) # Try Image.ANTIALIAS inplace of Image.NEAREST\n","\n","  else:\n","    image = image.resize(new_width_height)\n","\n","  if image.mode == \"RGBA\" and convert_RGB:\n","  \n","    new = Image.new(\"RGBA\", image.size, \"WHITE\") # Create a white rgba background\n","    new.paste(image, (0, 0), image) # Paste the image on the background.\n","    image = new.convert('RGB')\n","\n","  return image\n","\n","\n","\n","def load_image(path, resize_image_size = 1920):\n","    '''\n","    Load the image as tensor according to the format authors have used in the code\n","    '''\n","    if (\"https\" in path) or (\"http\" in path):\n","      image = Image.open(BytesIO(requests.get(path).content))\n","\n","    else:\n","      image = Image.open(path)\n","\n","    if image.mode != 'RGB':\n","      image = image.convert('RGB')\n","    \n","    if resize:\n","      image = resize(image, resize_image_size)\n","               \n","    return TF.to_tensor(image).to(DEVICE)\n","     "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4673,"status":"ok","timestamp":1681279843770,"user":{"displayName":"Sanjay K V","userId":"07954576096521181679"},"user_tz":-600},"id":"nTvgnv2Kmsv3"},"outputs":[],"source":["checkpoint_filepath = \"./pretrained_models/adobe_dpe/curl_validpsnr_23.073045286204017_validloss_0.0701291635632515_testpsnr_23.584083321292365_testloss_0.061363041400909424_epoch_510_model.pt\"\n","\n","# Build Model\n","net = model.CURLNet()\n","checkpoint = torch.load(checkpoint_filepath, map_location=DEVICE)\n","net.load_state_dict(checkpoint['model_state_dict'])\n","net.eval()\n","if DEVICE == 'cuda':\n","  net.cuda()\n","\n","\n","def evaluate(img, convert_uint = False):\n","    \"\"\"\n","    Evaluate the model per image instance. Image of Batch size 1. Can be used in API production\n","    \"\"\"\n","    img = load_image(img)\n","\n","    with torch.no_grad():\n","\n","        img = img.unsqueeze(0)\n","        img = torch.clamp(img, 0, 1)\n","\n","        net_output_img_example , _ = net(img)\n","\n","        net_output_img_example_numpy = net_output_img_example.squeeze(0).data.cpu().numpy()\n","        net_output_img_example_numpy = ImageProcessing.swapimdims_3HW_HW3(net_output_img_example_numpy)\n","        return (net_output_img_example_numpy* 255).astype(np.uint8) if convert_uint else net_output_img_example_numpy\n","     \n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"14dOXiEoawKTvyo-EXJUha5jtV-6EgTLg"},"id":"hXXY7Q9EmyMg","outputId":"954fa817-f8b2-47de-8c36-9fb0fbcd89cd"},"outputs":[],"source":["urls = [\"https://raw.githubusercontent.com/sanjay-kv/bigdatasociety-2023/main/7efb17b2-9437-42bd-9433-99d1efb8513e-1.jpg\",\n","      \"https://raw.githubusercontent.com/sanjay-kv/bigdatasociety-2023/main/d11edf57-97f5-4257-afdb-05294c9f2639-1.jpg\"\n","      ]\n","\n","%matplotlib inline\n","f, ax = plt.subplots(2,2, figsize = (30,20))\n","\n","for i, url in enumerate(urls):\n","\n","  result = evaluate(url, convert_uint = False) # gives you array between 0-1 so if you want an \"Image\", use 'convert_uint = True', then Image.fromarray(array).save(path)\n","\n","  ax[i][0].imshow(np.array(Image.open(BytesIO(requests.get(url).content)))) # Original image\n","  ax[i][1].imshow(result) # retouched\n","\n","  ax[i][0].set_title(\"Original Image\", fontsize=20)\n","  ax[i][1].set_title(\"Enhanced Image\", fontsize=20)\n","\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOn+Rh11FNzL6PZJe7B+6Ec","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}